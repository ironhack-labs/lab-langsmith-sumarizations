{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bb9c6d-7a1c-480a-93c9-acf847773163",
   "metadata": {
    "id": "52bb9c6d-7a1c-480a-93c9-acf847773163"
   },
   "source": [
    "# Lab | Summarization evaluation using LangSmith\n",
    "Let's revisit your capstone project 2? Well, sort of. Pick diffierent sets of data and re-run this notebook. Maybe parts of the dataset you used in your last project week. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications using LangSmith.\n",
    "\n",
    "What did you learn? - Let's discuss that in class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9",
   "metadata": {
    "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9"
   },
   "source": [
    "## LangSmith - LangChain evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HBXeckpYkuOZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBXeckpYkuOZ",
    "outputId": "152c0d37-0793-4582-b7a4-5c5693438859"
   },
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
   "metadata": {
    "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fab14f",
   "metadata": {
    "id": "a0fab14f"
   },
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"]=\"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"]=\"LANGCHAIN_API_KEY\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"]=\"langsmith_max_summarization-IronHack_Lab\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
   "metadata": {
    "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
    "tags": []
   },
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"langsmith_max_summarization-IronHack_Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
   "metadata": {
    "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing Client from Langsmith\n",
    "from langsmith import Client\n",
    "client = Client(api_key=LANGCHAIN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2",
   "metadata": {
    "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2"
   },
   "source": [
    "### Create Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0g6n5T59es3J",
   "metadata": {
    "id": "0g6n5T59es3J"
   },
   "outputs": [],
   "source": [
    "#pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
   "metadata": {
    "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "cnn_dataset = load_dataset(\n",
    "    \"ccdv/cnn_dailymail\", version\n",
    "    =\"3.0.0\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
   "metadata": {
    "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_prefix(example):\n",
    "    return {\n",
    "        **example,\n",
    "        \"article\": f\"Summarize this news:\\n{example['article']}\"\n",
    "    }\n",
    "\n",
    "#cnn_dataset = cnn_dataset.map(add_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
    "outputId": "26db6e15-b926-4191-b22e-faaf8bc2ce22",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
    "outputId": "88149ac4-a3ac-4cfd-bb72-afd2f04ad46d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
    "outputId": "4ae195a2-d6fd-42e1-e612-784248aba2b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get just a few news to test\n",
    "MAX_NEWS=10\n",
    "sample_cnn = cnn_dataset[\"test\"].select(range(MAX_NEWS)).map(add_prefix)\n",
    "\n",
    "sample_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ef576-ea25-446d-a99b-354678a274ba",
   "metadata": {
    "id": "bc0ef576-ea25-446d-a99b-354678a274ba"
   },
   "source": [
    "The dataset contains three columns: article, highlights, and id. To use LangSmith, we need to create a dataset in LangSmith format.\n",
    "\n",
    "LangSmith expects a prompt and a result. To achieve this, we will transform the article into a prompt by adding the prefix: \"Summarize this news.\" As a result, we will use the content of highlights, which represents the summaries created by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
    "outputId": "5aacecd4-afce-41ce-9c18-9802936ade4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sample_cnn[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8",
   "metadata": {
    "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8"
   },
   "source": [
    "Now We have the Dataset with the prompt and the Reference Summary, it is time to create a Dataset in LangSmith with this information.\n",
    "### Create the Dataset in Langsmith\n",
    "\n",
    "The dataset in LangSmith is composed of an input, which is the prompt passed to the model for evaluation, and an output, which should contain what we expect the model to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
   "metadata": {
    "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
   "metadata": {
    "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "input_key=['article']\n",
    "output_key=['highlights']\n",
    "\n",
    "NAME_DATASET=f\"Summarize_dataset_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "213f6dd87bbb4e0982209cd41bcdd69a",
      "709b97a26d1042fba0d043feb6b3d23f",
      "0d329af023444f39bb02e44afcf9a820",
      "fe26effa440c4b4da70c9934fe3c61a3",
      "3e2dad0ff3994eb88cd26a8ef28321f6",
      "1832077ef6944b2cb3c89e8e70383363",
      "9ce764fae94e4b6eabaf659b2dedf20c",
      "47e19055321347369046e9fb5981f471",
      "df3223c5d128440983857b519e839f71",
      "83102633cc31425590662d4bfe4289eb",
      "bf50c4d41c5d4b37964b17eb39da6115"
     ]
    },
    "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
    "outputId": "99959693-6650-4141-8648-3ef0b8e5950d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This creates the dataset in LangSmith with the content in sample_cnn - If you run this more than once you will get POST errors\n",
    "dataset = client.upload_dataframe(\n",
    "    df=sample_cnn,\n",
    "    input_keys=input_key,\n",
    "    output_keys=output_key,\n",
    "    name=NAME_DATASET,\n",
    "    description=\"Test Embedding distance between model summarizations\",\n",
    "    data_type=\"kv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2bd55-b6bc-467c-b481-48d46ad50441",
   "metadata": {
    "id": "ada2bd55-b6bc-467c-b481-48d46ad50441"
   },
   "source": [
    "In this image, we can see an example from the dataset once it's been registered in LangSmith.\n",
    "\n",
    "In the Input column, there is the prompt to be sent, while in the Output column, the expected output is stored.\n",
    "\n",
    "When performing the comparison, the model will be given the prompt, and the Cosine distance between its response and the one stored in the sample dataset will be calculated.\n",
    "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Dataset.jpg?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8278f53f-1a94-407c-846d-05c926737704",
   "metadata": {
    "id": "8278f53f-1a94-407c-846d-05c926737704"
   },
   "source": [
    "### Recovering Models From Hugging Face\n",
    "Let's retrieve both models from HuggingFace. A base T5 model and a model that has been fine-tuned using the training portion of this same dataset to generate summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q6Qjm3ESmDj8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6Qjm3ESmDj8",
    "outputId": "92c35810-d0c4-457a-f8b6-65d654ad0a41"
   },
   "outputs": [],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rInFwh-97i8C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rInFwh-97i8C",
    "outputId": "7dbb145f-a314-4bbe-9d72-e00c557e7e81"
   },
   "outputs": [],
   "source": [
    "!pip install langchain --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
   "metadata": {
    "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain_community.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
    "outputId": "63b908ff-ef52-49fc-86bc-c2f1a797da3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer_base = HuggingFaceHub(\n",
    "    repo_id=\"t5-base\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
   "metadata": {
    "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer_finetuned = HuggingFaceHub(\n",
    "    repo_id=\"flax-community/t5-base-cnn-dm\",\n",
    "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
    "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6",
   "metadata": {
    "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6"
   },
   "source": [
    "## Defining Evaluator\n",
    "The first step is to define an evaluator, where we specify the variables we want to evaluate. In our case, I have chosen to measure only the \"embedding_distance.\"\n",
    "\n",
    "I've left the \"string_distance\" as a comment in case you want to conduct a test with two evaluations instead of one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EKkmSZXUmWRo",
   "metadata": {
    "id": "EKkmSZXUmWRo"
   },
   "outputs": [],
   "source": [
    "!pip install -q rapidfuzz==3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soU2o8XWxnVm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soU2o8XWxnVm",
    "outputId": "79adc71a-1a7a-4eb9-d122-7d3ace923503"
   },
   "outputs": [],
   "source": [
    "!pip install langsmith --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
   "metadata": {
    "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.smith import run_on_dataset, RunEvalConfig\n",
    "# !pip install -q rapidfuzz==3.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iuvTtG6k0wJd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuvTtG6k0wJd",
    "outputId": "f8291365-db8d-437a-ca18-baa762075751"
   },
   "outputs": [],
   "source": [
    "pip install pydantic==2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V-K3drs9x3bf",
   "metadata": {
    "id": "V-K3drs9x3bf"
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langsmith import Client\n",
    "#from langsmith.evaluation.config import RunEvalConfig\n",
    "from langchain.smith.evaluation.config import RunEvalConfig\n",
    "#from langsmith.evaluation import RunEvalConfig\n",
    "#from langchain.evaluation.embedding_distance import EmbeddingDistanceEvaluator\n",
    "#from langchain.smith import EmbeddingDistanceEvaluator\n",
    "#from langchain.evaluation.string_distance import StringDistanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
   "metadata": {
    "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We are using just one of the multiple evaluator avaiable on LangSmith.\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        \"embedding_distance\",\n",
    "        #\"string_distance\"\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee666c30-d958-45b1-802c-7034dd13b42b",
   "metadata": {
    "id": "ee666c30-d958-45b1-802c-7034dd13b42b"
   },
   "source": [
    "### Running Evaluator\n",
    "With the same configuration, we can launch two evaluations on the same dataset. One for each of the chosen models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cBKwoOqs-MfU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBKwoOqs-MfU",
    "outputId": "2cec4f6d-4ef7-433b-dd75-c5e29ebfd68f"
   },
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c75c07-8351-465f-af15-a1abe17968f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67c75c07-8351-465f-af15-a1abe17968f9",
    "outputId": "fc5c0596-7ad2-4d2a-c2b2-a23a17a34b06",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "base_t5_results = run_on_dataset(\n",
    "    client=client,\n",
    "    project_name=project_name,\n",
    "    dataset_name=NAME_DATASET,\n",
    "    llm_or_chain_factory=summarizer_base,\n",
    "    evaluation=evaluation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
    "outputId": "998227ed-4e2b-4f95-88d9-1cf96d02a500",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ignore the error shown below\n",
    "project_name = f\"T5-FineTuned {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "finetuned_t5_results = run_on_dataset(\n",
    "    client=client,\n",
    "    project_name=project_name,\n",
    "    dataset_name=NAME_DATASET,\n",
    "    llm_or_chain_factory=summarizer_finetuned,\n",
    "    evaluation=evaluation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159",
   "metadata": {
    "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159"
   },
   "source": [
    "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Tests.jpg?raw=true\">\n",
    "\n",
    "In the image below you can see the comparision between two tests.\n",
    "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareTestst.jpg?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xn6jeX7u_4MR",
   "metadata": {
    "id": "Xn6jeX7u_4MR"
   },
   "source": [
    "Well, since it has been so straightforward, why don't we try to make the comparison with an OpenAI model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PNvDLFGDAPnH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNvDLFGDAPnH",
    "outputId": "25f6c823-f8ed-494b-bdd7-3f3c8e766b5a"
   },
   "outputs": [],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a97ac1-623e-4d28-a78b-c807af89c918",
   "metadata": {
    "id": "84a97ac1-623e-4d28-a78b-c807af89c918"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "open_aillm=OpenAI(temperature=0.0, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suc0G-9W94Qj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suc0G-9W94Qj",
    "outputId": "378b4623-4783-43f9-ce9c-2dfcd23ea717",
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_name = f\"OpenAI {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "finetuned_t5_results = run_on_dataset(\n",
    "    client=client,\n",
    "    project_name=project_name,\n",
    "    dataset_name=NAME_DATASET,\n",
    "    llm_or_chain_factory=open_aillm,\n",
    "    evaluation=evaluation_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B15V_-3pBvOK",
   "metadata": {
    "id": "B15V_-3pBvOK"
   },
   "source": [
    "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareOpenAI_HF.jpg?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fUeZWvLMCOBw",
   "metadata": {
    "id": "fUeZWvLMCOBw"
   },
   "source": [
    "The experiment with the OpenAI model has yielded the best results. But, be aware! As we can see, there is a cost involved since we are using an API, and it needs to be paid for.\n",
    "\n",
    "Another crucial piece of information is that we can view performance data for the models. This data could also be useful for minimally evaluating our inference server."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d329af023444f39bb02e44afcf9a820": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47e19055321347369046e9fb5981f471",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df3223c5d128440983857b519e839f71",
      "value": 1
     }
    },
    "1832077ef6944b2cb3c89e8e70383363": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "213f6dd87bbb4e0982209cd41bcdd69a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_709b97a26d1042fba0d043feb6b3d23f",
       "IPY_MODEL_0d329af023444f39bb02e44afcf9a820",
       "IPY_MODEL_fe26effa440c4b4da70c9934fe3c61a3"
      ],
      "layout": "IPY_MODEL_3e2dad0ff3994eb88cd26a8ef28321f6"
     }
    },
    "3e2dad0ff3994eb88cd26a8ef28321f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47e19055321347369046e9fb5981f471": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "709b97a26d1042fba0d043feb6b3d23f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1832077ef6944b2cb3c89e8e70383363",
      "placeholder": "​",
      "style": "IPY_MODEL_9ce764fae94e4b6eabaf659b2dedf20c",
      "value": "Creating CSV from Arrow format: 100%"
     }
    },
    "83102633cc31425590662d4bfe4289eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ce764fae94e4b6eabaf659b2dedf20c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf50c4d41c5d4b37964b17eb39da6115": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df3223c5d128440983857b519e839f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe26effa440c4b4da70c9934fe3c61a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83102633cc31425590662d4bfe4289eb",
      "placeholder": "​",
      "style": "IPY_MODEL_bf50c4d41c5d4b37964b17eb39da6115",
      "value": " 1/1 [00:00&lt;00:00, 38.64ba/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
