{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52bb9c6d-7a1c-480a-93c9-acf847773163",
      "metadata": {
        "id": "52bb9c6d-7a1c-480a-93c9-acf847773163"
      },
      "source": [
        "# Lab | Summarization evaluation using LangSmith\n",
        "Let's revisit your capstone project 2? Well, sort of. Pick diffierent sets of data and re-run this notebook. Maybe parts of the dataset you used in your last project week. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications using LangSmith.\n",
        "\n",
        "What did you learn? - Let's discuss that in class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9",
      "metadata": {
        "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9"
      },
      "source": [
        "## LangSmith - LangChain evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AHI13P9c6TzS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHI13P9c6TzS",
        "outputId": "bf298b64-5229-4978-e444-128c33835423"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
      "metadata": {
        "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
      "metadata": {
        "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langsmith_max-test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
        "outputId": "994a9112-4ad2-4579-b52f-c6172c0235e5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Importing Client from Langsmith\n",
        "from langsmith import Client\n",
        "client = Client(api_key=LANGCHAIN_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2",
      "metadata": {
        "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2"
      },
      "source": [
        "### Create Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jdTXWYRR6eNJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdTXWYRR6eNJ",
        "outputId": "aab4fcf2-fcc9-4443-d6f7-66f627bf25d9"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
        "outputId": "3228227f-ef64-4856-ad84-f8ed7fcd30d8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "cnn_dataset = load_dataset(\n",
        "    \"ccdv/cnn_dailymail\", version\n",
        "    =\"3.0.0\",\n",
        "    trust_remote_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
      "metadata": {
        "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def add_prefix(example):\n",
        "    return {\n",
        "        **example,\n",
        "        \"article\": f\"Summarize this news:\\n{example['article']}\"\n",
        "    }\n",
        "\n",
        "#cnn_dataset = cnn_dataset.map(add_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
        "outputId": "0326ffa7-2250-478e-9fb9-fbaafadd738e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cnn_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
        "outputId": "7770672c-9543-4147-c9a6-aaccbce3d68b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cnn_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
        "outputId": "f4c3af9f-3dea-4e8b-9570-e34ba0be44af",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Get just a few news to test\n",
        "MAX_NEWS=10\n",
        "sample_cnn = cnn_dataset[\"test\"].select(range(MAX_NEWS)).map(add_prefix)\n",
        "\n",
        "sample_cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0ef576-ea25-446d-a99b-354678a274ba",
      "metadata": {
        "id": "bc0ef576-ea25-446d-a99b-354678a274ba"
      },
      "source": [
        "The dataset contains three columns: article, highlights, and id. To use LangSmith, we need to create a dataset in LangSmith format.\n",
        "\n",
        "LangSmith expects a prompt and a result. To achieve this, we will transform the article into a prompt by adding the prefix: \"Summarize this news.\" As a result, we will use the content of highlights, which represents the summaries created by humans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
        "outputId": "974a984b-eb76-4920-ad60-0d17fce4cbf8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(sample_cnn[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8",
      "metadata": {
        "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8"
      },
      "source": [
        "Now We have the Dataset with the prompt and the Reference Summary, it is time to create a Dataset in LangSmith with this information.\n",
        "### Create the Dataset in Langsmith\n",
        "\n",
        "The dataset in LangSmith is composed of an input, which is the prompt passed to the model for evaluation, and an output, which should contain what we expect the model to return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
      "metadata": {
        "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
      "metadata": {
        "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "input_key=['article']\n",
        "output_key=['highlights']\n",
        "\n",
        "NAME_DATASET=f\"Summarize_dataset_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ZEU5SwxCHit",
      "metadata": {
        "id": "2ZEU5SwxCHit"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Replace 'YOUR_LANGCHAIN_API_KEY' with your actual API key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \n",
        "\n",
        "from langsmith import Client\n",
        "client = Client(api_key=os.environ.get(\"LANGCHAIN_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yuXQdhqM9lTA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuXQdhqM9lTA",
        "outputId": "369d0c86-f203-4565-d1c5-c07836eb9742"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.environ.get(\"LANGCHAIN_API_KEY\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2dc135bdaaa3429d976d80af785e5243",
            "fad53761b2764778b23747ffce9fb4bd",
            "b2cb6752d1184f1ca931334ad4c30c84",
            "cff9d06a0efc46b4a1ac58fa8431a812",
            "334175ca1c584607bd6d79aa10252e65",
            "a1b223f2a42f46b4aea473020c7e6634",
            "11b6a8cfe11e4c95b47ea1c837c06db8",
            "52337d5ffad6419faa8ffec69a32c5a0",
            "191fa2d99523451c8d8390c6804195af",
            "8be2857d76784496a8d0c0fc747b3137",
            "66452fb14c9e4abd9ff326ec1239e2ec"
          ]
        },
        "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
        "outputId": "535f0963-710c-4c25-c3e1-031438b89afa",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "#This creates the dataset in LangSmith with the content in sample_cnn - If you run this more than once you will get POST errors\n",
        "dataset = client.upload_dataframe(\n",
        "    df=sample_cnn,\n",
        "    input_keys=input_key,\n",
        "    output_keys=output_key,\n",
        "    name=NAME_DATASET,\n",
        "    description=\"Test Embedding distance between model summarizations\",\n",
        "    data_type=\"kv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada2bd55-b6bc-467c-b481-48d46ad50441",
      "metadata": {
        "id": "ada2bd55-b6bc-467c-b481-48d46ad50441"
      },
      "source": [
        "In this image, we can see an example from the dataset once it's been registered in LangSmith.\n",
        "\n",
        "In the Input column, there is the prompt to be sent, while in the Output column, the expected output is stored.\n",
        "\n",
        "When performing the comparison, the model will be given the prompt, and the Cosine distance between its response and the one stored in the sample dataset will be calculated.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Dataset.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8278f53f-1a94-407c-846d-05c926737704",
      "metadata": {
        "id": "8278f53f-1a94-407c-846d-05c926737704"
      },
      "source": [
        "### Recovering Models From Hugging Face\n",
        "Let's retrieve both models from HuggingFace. A base T5 model and a model that has been fine-tuned using the training portion of this same dataset to generate summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qtTkZdceCyp3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qtTkZdceCyp3",
        "outputId": "f98298e9-fc8f-46b9-c1d7-d3e7c591c04c"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
      "metadata": {
        "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "qE8adX3KHeE-",
      "metadata": {
        "id": "qE8adX3KHeE-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] =   # Replace with your actual token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bjtUmwBOIVM-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjtUmwBOIVM-",
        "outputId": "70570602-030f-49ff-8a50-24f5b31b73cb"
      },
      "outputs": [],
      "source": [
        "# print hugging api key value\n",
        "\n",
        "print(os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iqesjSCbL14u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqesjSCbL14u",
        "outputId": "4c4596b8-93c5-493e-b61c-f921331f3b0c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Assuming your Hugging Face token is stored in a .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Get your Hugging Face token from the environment variable\n",
        "HUGGINGFACEHUB_API_TOKEN = \n",
        "# If the token is not found, set it manually\n",
        "if HUGGINGFACEHUB_API_TOKEN is None:\n",
        "    HUGGINGFACEHUB_API_TOKEN =   # Replace with your actual token\n",
        "\n",
        "# Now use this token in your HuggingFaceHub instantiation\n",
        "summarizer_base = HuggingFaceHub(\n",
        "    repo_id=\"t5-base\",\n",
        "    model_kwargs={\"temperature\": 0, \"max_length\": 180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
      "metadata": {
        "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "summarizer_base = HuggingFaceHub(\n",
        "    repo_id=\"t5-base\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
      "metadata": {
        "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
        "tags": []
      },
      "outputs": [],
      "source": [
        "summarizer_finetuned = HuggingFaceHub(\n",
        "    repo_id=\"flax-community/t5-base-cnn-dm\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6",
      "metadata": {
        "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6"
      },
      "source": [
        "## Defining Evaluator\n",
        "The first step is to define an evaluator, where we specify the variables we want to evaluate. In our case, I have chosen to measure only the \"embedding_distance.\"\n",
        "\n",
        "I've left the \"string_distance\" as a comment in case you want to conduct a test with two evaluations instead of one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DzVMLgKnUYaE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzVMLgKnUYaE",
        "outputId": "b751cf6f-bbcd-49dc-9a90-e7a2b18695e1"
      },
      "outputs": [],
      "source": [
        "pip install pydantic==2.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
      "metadata": {
        "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.smith import run_on_dataset, RunEvalConfig\n",
        "#!pip install -q rapidfuzz==3.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
      "metadata": {
        "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#We are using just one of the multiple evaluator avaiable on LangSmith.\n",
        "\n",
        "evaluation_config = RunEvalConfig(\n",
        "    evaluators=[\n",
        "        \"embedding_distance\",\n",
        "        #\"string_distance\"\n",
        "    ],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee666c30-d958-45b1-802c-7034dd13b42b",
      "metadata": {
        "id": "ee666c30-d958-45b1-802c-7034dd13b42b"
      },
      "source": [
        "### Running Evaluator\n",
        "With the same configuration, we can launch two evaluations on the same dataset. One for each of the chosen models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tp3dcWAlZaSX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp3dcWAlZaSX",
        "outputId": "b04b312a-e8f2-4153-c580-db7381478e61"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uGtGvFAeY9St",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGtGvFAeY9St",
        "outputId": "128c08f4-a97b-4652-aa15-2d9cbe01f180"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Store your API key securely in an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \n",
        "\n",
        "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "# Retrieve the API key from the environment variable\n",
        "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Check if the key is retrieved successfully\n",
        "if openai_api_key is None:\n",
        "    raise ValueError(\"OPENAI_API_KEY environment variable not set. Please set it with your OpenAI API key.\")\n",
        "\n",
        "base_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_base,\n",
        "    evaluation=evaluation_config,\n",
        "    # Pass the API key to the run_on_dataset function\n",
        "    llm_kwargs={\"openai_api_key\": openai_api_key}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c75c07-8351-465f-af15-a1abe17968f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c75c07-8351-465f-af15-a1abe17968f9",
        "outputId": "02d2c5d6-9673-4845-a9e2-9a21376c8dce",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "base_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_base,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
        "outputId": "290e4010-8e92-4deb-9fc6-e6990fb74106",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Ignore the error shown below\n",
        "project_name = f\"T5-FineTuned {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_finetuned,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159",
      "metadata": {
        "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Tests.jpg?raw=true\">\n",
        "\n",
        "In the image below you can see the comparision between two tests.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareTestst.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xn6jeX7u_4MR",
      "metadata": {
        "id": "Xn6jeX7u_4MR"
      },
      "source": [
        "Well, since it has been so straightforward, why don't we try to make the comparison with an OpenAI model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W93Bdic0cKDe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W93Bdic0cKDe",
        "outputId": "2f2768e8-6bf4-41a5-efbe-2fbd8122f4bc"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "84a97ac1-623e-4d28-a78b-c807af89c918",
      "metadata": {
        "id": "84a97ac1-623e-4d28-a78b-c807af89c918"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "open_aillm=OpenAI(temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suc0G-9W94Qj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suc0G-9W94Qj",
        "outputId": "fca82382-ed6a-4d13-9c71-b3266332d5d3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "project_name = f\"OpenAI {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=open_aillm,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B15V_-3pBvOK",
      "metadata": {
        "id": "B15V_-3pBvOK"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareOpenAI_HF.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fUeZWvLMCOBw",
      "metadata": {
        "id": "fUeZWvLMCOBw"
      },
      "source": [
        "The experiment with the OpenAI model has yielded the best results. But, be aware! As we can see, there is a cost involved since we are using an API, and it needs to be paid for.\n",
        "\n",
        "Another crucial piece of information is that we can view performance data for the models. This data could also be useful for minimally evaluating our inference server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VdBNye7teYwf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdBNye7teYwf",
        "outputId": "a5b768ec-e365-4c60-d8ee-e0cfe8222a79"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import getpass\n",
        "github_token = getpass.getpass('Enter your GitHub token: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "Al_NIy0Gd7h9",
      "metadata": {
        "id": "Al_NIy0Gd7h9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GITHUB_TOKEN'] = \"\"  # Replace with your token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dt7tBoGXeKSM",
      "metadata": {
        "id": "dt7tBoGXeKSM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11b6a8cfe11e4c95b47ea1c837c06db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "191fa2d99523451c8d8390c6804195af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dc135bdaaa3429d976d80af785e5243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fad53761b2764778b23747ffce9fb4bd",
              "IPY_MODEL_b2cb6752d1184f1ca931334ad4c30c84",
              "IPY_MODEL_cff9d06a0efc46b4a1ac58fa8431a812"
            ],
            "layout": "IPY_MODEL_334175ca1c584607bd6d79aa10252e65"
          }
        },
        "334175ca1c584607bd6d79aa10252e65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52337d5ffad6419faa8ffec69a32c5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66452fb14c9e4abd9ff326ec1239e2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be2857d76784496a8d0c0fc747b3137": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b223f2a42f46b4aea473020c7e6634": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2cb6752d1184f1ca931334ad4c30c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52337d5ffad6419faa8ffec69a32c5a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_191fa2d99523451c8d8390c6804195af",
            "value": 1
          }
        },
        "cff9d06a0efc46b4a1ac58fa8431a812": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be2857d76784496a8d0c0fc747b3137",
            "placeholder": "​",
            "style": "IPY_MODEL_66452fb14c9e4abd9ff326ec1239e2ec",
            "value": " 1/1 [00:00&lt;00:00, 20.43ba/s]"
          }
        },
        "fad53761b2764778b23747ffce9fb4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b223f2a42f46b4aea473020c7e6634",
            "placeholder": "​",
            "style": "IPY_MODEL_11b6a8cfe11e4c95b47ea1c837c06db8",
            "value": "Creating CSV from Arrow format: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
